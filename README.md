# ğŸ  Advanced House Price Prediction (Kaggle Competition)

This project is my solution to the [Advanced House Prices - Kaggle Competition](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques). The goal is to predict the final price of residential homes based on various features describing the properties.

---

## ğŸ“Œ Problem Statement

Predict the sale price of houses using 79 explanatory variables describing nearly every aspect of residential homes in Ames, Iowa.

---

## ğŸ§  My Approach

### ğŸ§¹ Data Preprocessing
- Handled missing values and outliers
- Removed irrelevant columns with little to no value
- Dropped features with high correlation to prevent multicollinearity
- Created new features and fixed skewed distributions

### ğŸ“Š Exploratory Data Analysis (EDA)
- Checked feature distributions and relationships with the target variable
- Analyzed correlation matrix and feature importance

### âš™ï¸ Feature Engineering
- Applied encoding techniques:
  - **Ordinal encoding** for features with inherent order (e.g. quality, condition)
  - **One-hot encoding** for nominal features without order (e.g. neighborhood)
- Handled skewness and applied log transformation where needed
- Used **StandardScaler** to normalize numerical features

### ğŸ§ª Modeling & Evaluation
Trained and evaluated multiple regression models:

- Linear Regression
- Ridge, Lasso, ElasticNet
- K-Nearest Neighbors (KNN)
- Decision Tree (CART)
- Support Vector Regression (SVR)

Then evaluated ensemble models:

- Random Forest
- Extra Trees
- AdaBoost
- Gradient Boosting

Evaluation metric: `negative mean squared error (neg_mean_squared_error)` using cross-validation.

### âœ… Final Model
The **Ridge Regression** model had the **lowest mean squared error**, and was selected as the final model.

---

## ğŸ›  Tools Used

- Python
- Pandas, NumPy
- Matplotlib, Seaborn
- Scikit-learn

---

## ğŸ“‚ Project Structure

